{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4a1198c2-16d8-4906-8b9c-85da32f780fd"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import keras.utils as image\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "from tensorflow import keras\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import layers,models, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.applications import ResNet50, MobileNetV3Small\n",
    "from tensorflow.keras.applications import MobileNetV2, InceptionV3, VGG16 , VGG19\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization \n",
    "from tensorflow.keras.layers import Lambda\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "tf.get_logger().setLevel('INFO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "re2g1khU_s_D",
    "outputId": "d113755e-e4cc-4c67-9bd3-8acc60bc91cc"
   },
   "outputs": [],
   "source": [
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU found')\n",
    "else:\n",
    "    print('Default GPU device: {}' .format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Images Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57c3ac64-a987-4a66-b47e-a74cf4113ca2"
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aedc6245-408c-4c6a-9f14-12a5fb3bb796"
   },
   "outputs": [],
   "source": [
    "def data(folders):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    names = []\n",
    "    for folder in folders:\n",
    "        for img in load_images_from_folder(folder):\n",
    "            imgs.append(img)\n",
    "\n",
    "            if 'CaS' in folder:\n",
    "                labels.append('CaS')\n",
    "            elif 'CoS' in folder:\n",
    "                labels.append('CoS')\n",
    "            elif 'Gum' in folder:\n",
    "                labels.append('Gum')\n",
    "            elif 'MC' in folder:\n",
    "                labels.append('MC')\n",
    "            elif 'OC' in folder:\n",
    "                labels.append('OC')\n",
    "            elif 'OLP' in folder:\n",
    "                labels.append('OLP')\n",
    "            elif 'OT' in folder:\n",
    "                labels.append('OT')\n",
    "            else:\n",
    "                print(\"error\")\n",
    "\n",
    "        for name in os.listdir(folder):\n",
    "            names.append(os.path.join(folder, name))\n",
    "\n",
    "    names = pd.Series(names, name= 'name')\n",
    "    imgs = pd.Series(imgs, name='image', dtype= np.float32)\n",
    "    labels = pd.Series(labels, name=\"label\")\n",
    "\n",
    "    image_df = pd.concat([names, imgs, labels], axis=1)\n",
    "\n",
    "    return image_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d7e85cf-e30a-4dd4-a77c-9bc2cea4138d"
   },
   "outputs": [],
   "source": [
    "path = \"Teeth_Dataset/Training\"\n",
    "folders = [os.path.join(path, x) for x in os.listdir(path)]\n",
    "train_df = data(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93568485-8c46-480b-b6fe-31e72e71e2c1"
   },
   "outputs": [],
   "source": [
    "path = \"Teeth_Dataset/Testing\"\n",
    "folders = [os.path.join(path, x) for x in os.listdir(path)]\n",
    "test_df = data(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a467dafb-b180-40bc-8c5d-61b9af687aa0"
   },
   "outputs": [],
   "source": [
    "path = \"Teeth_Dataset/Validation\"\n",
    "folders = [os.path.join(path, x) for x in os.listdir(path)]\n",
    "validation_df = data(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24d9a4a7-9345-4553-a0b8-7c14cbc52972"
   },
   "source": [
    "# Visulaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ccf9b70-38ad-4ddb-8673-14a79f58bf10"
   },
   "outputs": [],
   "source": [
    "label_counts = train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82b8ad69-c80b-4009-85c1-b28d9aa524ff",
    "outputId": "6d7bec11-ca13-47aa-b631-05c93870bdf1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values, alpha=0.8, palette='dark:salmon_r')\n",
    "\n",
    "plt.title('Distribution of Labels in Image Dataset', fontsize=16)\n",
    "plt.xlabel('Label', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41cd3789-eec6-4073-9a9e-7542f0c59f22",
    "outputId": "84a9703c-a43c-4d20-9746-25c82e1fa330"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20, 10))\n",
    "random_values = np.random.randint(0, len(train_df), 16)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize = (10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(train_df.name[random_values[i]]))\n",
    "    ax.set_title(train_df.label[random_values[i]])\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40145e91-1de6-47c4-a83a-9f0b316c55de"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9064be04-f552-49ef-b7da-de82c21ae0d8"
   },
   "outputs": [],
   "source": [
    "train_path = train_df.pop(\"name\").astype(str)\n",
    "valid_path = validation_df.pop(\"name\").astype(str)\n",
    "test_path = test_df.pop(\"name\").astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukLx9BMiw7lV",
    "outputId": "148ad5fe-ef41-4fe5-8a32-bd893b8f7d46"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"Teeth_Dataset/Training\",\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    \"Teeth_Dataset/Validation\",\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_datagen_generator = train_datagen.flow_from_directory(\n",
    "    \"Teeth_Dataset/Testing\",\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e04fd542-d68e-4d74-bf57-fdd0e87a3b44",
    "outputId": "98deee95-e3c6-4401-dd9b-1e4d7eed9373"
   },
   "outputs": [],
   "source": [
    "# input_shape = [224, 224, 3]\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "\n",
    "#     layers.Conv2D(filters= 64, kernel_size= (3,3), activation= \"relu\", input_shape= input_shape ),\n",
    "#     layers.MaxPool2D(pool_size=(2,2), strides= 2),\n",
    "#     layers.Conv2D(filters= 128, kernel_size= (3,3), activation= \"relu\", input_shape= input_shape ),\n",
    "#     layers.MaxPool2D(pool_size=(2,2), strides= 2),\n",
    "#     layers.Conv2D(filters= 256, kernel_size= (3,3), activation= \"relu\", input_shape= input_shape ),\n",
    "#     layers.MaxPool2D(pool_size=(2,2), strides= 2),\n",
    "\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(units= 1000, activation= \"relu\"),\n",
    "#     layers.Dropout(.5),\n",
    "#     layers.Dense(units= 200, activation= \"relu\"),\n",
    "\n",
    "\n",
    "#     layers.Dense(7, activation= \"softmax\")\n",
    "\n",
    "\n",
    "# ])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer= keras.optimizers.Adamax(learning_rate=.0001),\n",
    "#     loss = \"categorical_crossentropy\",\n",
    "#     metrics= [\"accuracy\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create checkpoint callback\n",
    "# checkpoint_path = \"model_checkpoint.keras\"\n",
    "# checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "#                                       monitor=\"val_accuracy\",\n",
    "#                                       save_best_only=True)\n",
    "\n",
    "# # Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "# early_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
    "#                                patience = 10,\n",
    "#                                restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=10,\n",
    "#     validation_data= valid_generator,\n",
    "#     callbacks=[\n",
    "#         early_stopping,\n",
    "#         reduce_lr, \n",
    "#         checkpoint_callback\n",
    "#     ]\n",
    "#  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = [224, 224, 3]\n",
    "vgg = VGG16(input_shape= input_shape, include_top= False, classes=1000, pooling= \"max\")\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing Dense Layers\n",
    "model_without_last_layer = tf.keras.Model(inputs=vgg.input, outputs=vgg.layers[-2].output)\n",
    "model_without_last_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing\n",
    "for lay in model_without_last_layer.layers:\n",
    "    lay.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint callback\n",
    "checkpoint_path = \"VGG16_Checkpoint.h5\"\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "                                      monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True)\n",
    "\n",
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
    "                               patience = 5,\n",
    "                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x, input_shape=(224, 224, 3)))\n",
    "\n",
    "model.add(model_without_last_layer)\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(350, (3, 3), activation= \"relu\", padding= \"same\"))\n",
    "model.add(tf.keras.layers.SpatialDropout2D(.2))\n",
    "\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv2D(100, (3, 3), activation= \"relu\"))\n",
    "model.add(tf.keras.layers.SpatialDropout2D(.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(50, (3, 3), activation= \"relu\"))\n",
    "model.add(tf.keras.layers.SpatialDropout2D(.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(450, activation= \"relu\"))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "model.add(Dense(150, activation= \"relu\"))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "\n",
    "model.add(Dense(50, activation= \"relu\"))\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "model.add(Dense(7, activation= \"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer= keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics= [\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data= valid_generator,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        reduce_lr, \n",
    "        checkpoint_callback\n",
    "    ]\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5c47aad-f543-4253-9226-d6fb58798998",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test_datagen_generator , verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "223dd6fa-f7ac-40d5-8765-0ec5b910772b"
   },
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ba4f13b3-63f0-44be-8414-72187e8dccf8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# keras.models.save_model(model, \"vgg16_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"vgg16_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(img_path, model):\n",
    "\n",
    "    # Preprocessing the image\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.image.resize(img, [224,224])\n",
    "    img = img/255.0\n",
    "    #img = preprocess_input(x)\n",
    "\n",
    "    y = model.predict(img)\n",
    "\n",
    "    return np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_predict(test_path[1027], model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5570817,
     "sourceId": 9212907,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
